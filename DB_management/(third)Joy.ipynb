{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "client.database_names()\n",
    "# Create database and collection objects for convenience\n",
    "db = client.data_diggers\n",
    "collection = db.reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x7f983d907120>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('../cities.json', 'r') as f:\n",
    "    cities = json.load(f)\n",
    "collection.drop()\n",
    "collection.insert_many(cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a2805ea2ece250ddc329938'), 'city_name': 'Aberdeen', 'latitude': '57.13514', 'region': 'Aberdeen City', 'uk_region': 'Scotland', 'longitude': '-2.11731'}\n"
     ]
    }
   ],
   "source": [
    "print(collection.find_one())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.education\n",
    "import json\n",
    "with open('../normalize_dataset/education.json', 'r') as f:\n",
    "    education = json.load(f)\n",
    "\n",
    "l = []\n",
    "for edu in education:\n",
    "    l.append({'city_name':edu,'school_number_normalize_maxmin':education[edu]})\n",
    "\n",
    "collection.drop()\n",
    "collection.insert_many(l)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.hospitals\n",
    "import json\n",
    "with open('../normalize_dataset/hospitals.json', 'r') as f:\n",
    "    hospitals = json.load(f)\n",
    "\n",
    "l = []\n",
    "for hos in hospitals:\n",
    "    l.append({'city_name':hos,'hospitals_number_normalize_maxmin':hospitals[hos]})\n",
    "\n",
    "collection.drop()\n",
    "collection.insert_many(l)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.pubs\n",
    "import json\n",
    "with open('../normalize_dataset/pubs.json', 'r') as f:\n",
    "    pubs = json.load(f)\n",
    "\n",
    "l = []\n",
    "for pub in pubs:\n",
    "    l.append({'city_name':pub,'pubs_number_normalize_maxmin':pubs[pub]})\n",
    "# l\n",
    "collection.drop()\n",
    "collection.insert_many(l)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rail_way station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.railway_station\n",
    "import json\n",
    "with open('../normalize_dataset/railway_station.json', 'r') as f:\n",
    "    stations = json.load(f)\n",
    "\n",
    "l = []\n",
    "for station in stations:\n",
    "    l.append({'city_name':station,'stations_number_normalize_maxmin':stations[station]})\n",
    "\n",
    "collection.drop()\n",
    "collection.insert_many(l)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['houseprice_collection',\n",
       " 'education',\n",
       " 'training_data',\n",
       " 'unemployment',\n",
       " 'trafficNoise',\n",
       " 'hospitals',\n",
       " 'population_collection',\n",
       " 'gva_collection',\n",
       " 'UniRank',\n",
       " 'happinessRank',\n",
       " 'railway_station',\n",
       " 'pubs',\n",
       " 'roadTraffic',\n",
       " 'reference',\n",
       " 'TotalJobs']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection = db.training_data\n",
    "collection.drop()\n",
    "collection.insert_many(cities)\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# house_price\n",
    "new_collection = db.houseprice_collection\n",
    "# print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'house_price': collect['Normalization']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'house_price': collect['Normalization']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# school_number\n",
    "new_collection = db.education\n",
    "# print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'school_number': collect['school_number_normalize_maxmin']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'school_number': collect['school_number_normalize_maxmin']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unemployment\n",
    "new_collection = db.unemployment\n",
    "# print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'unemployment': float(collect['Unemployment_norm'])}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'unemployment': float(collect['Unemployment_norm'])}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5cf2ece256aa224e5b9'), 'city_name': 'Stockton-on-Tees', 'Number of people exposed to traffic noise': 9100.0, 'Normalized value of Number of people exposed to traffic noise': -0.26221699976832685}\n"
     ]
    }
   ],
   "source": [
    "# trafficNoise\n",
    "new_collection = db.trafficNoise\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'traffic_noise': collect['Normalized value of Number of people exposed to traffic noise']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'traffic_noise': collect['Normalized value of Number of people exposed to traffic noise']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a2805eb2ece250ddc32a531'), 'city_name': 'Barnstaple', 'hospitals_number_normalize_maxmin': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# hospitals\n",
    "new_collection = db.hospitals\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'hospitals_number': collect['hospitals_number_normalize_maxmin']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'hospitals_number': collect['hospitals_number_normalize_maxmin']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5e82ece256a8a3b9d40'), 'city_name': 'Aberdeen', 'countries': 'United Kingdom', 'population': '222793', 'N_population': '-0.260979594'}\n"
     ]
    }
   ],
   "source": [
    "# population_collection\n",
    "new_collection = db.population_collection\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'population': float(collect['N_population'])}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'population': float(collect['N_population'])}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5f92ece256a8a3b9f38'), 'city_name': 'Aberdeen', 'GVA_per_worker_per_month': '56800', 'GVA_norm': '1.6172106581', 'GVA_max_min_norm': '0.6071428571'}\n"
     ]
    }
   ],
   "source": [
    "# gva_collection\n",
    "new_collection = db.gva_collection\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'GVA': float(collect['GVA_max_min_norm'])}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'GVA': float(collect['GVA_max_min_norm'])}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "#UniRank\n",
    "new_collection = db.UniRank\n",
    "# for i in new_collection.find():\n",
    "#     print(i)\n",
    "print(new_collection.count())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'best_Uni_ranking': collect['total_jobs_normalized_value']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'best_Uni_ranking':collect['total_jobs_normalized_value']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5d72ece256aa224e5f5'), 'city_name': 'United Kingdom', 'Average happiness rating': 7.38, 'Sample size': 304740.0, 'Normalized value of happiness ranking': 0.38}\n"
     ]
    }
   ],
   "source": [
    "#happinessRank\n",
    "new_collection = db.happinessRank\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'happiness': float(collect['Normalized value of happiness ranking'])}})\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'sample':int(collect['Sample size'])}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'happiness':float(collect['Normalized value of happiness ranking'])}})\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'sample':int(collect['Sample size'])}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a2805eb2ece250ddc32a8b1'), 'city_name': 'Mendip', 'stations_number_normalize_maxmin': 0.0}\n"
     ]
    }
   ],
   "source": [
    "# railway_station\n",
    "new_collection = db.railway_station\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'stations_number': collect['stations_number_normalize_maxmin']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'stations_number':collect['stations_number_normalize_maxmin']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a2805eb2ece250ddc32a739'), 'city_name': 'Mendip', 'pubs_number_normalize_maxmin': 0.25073746312684364}\n"
     ]
    }
   ],
   "source": [
    "# pubs\n",
    "new_collection = db.pubs\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'pubs_number': collect['pubs_number_normalize_maxmin']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'pubs_number':collect['pubs_number_normalize_maxmin']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5c42ece256aa224e51a'), 'city_name': 'County Durham', 'Delay 2015': 21.2, 'Delay 2016': 22.4, 'Delay_2015_normalized_value': -0.8983897493709471, 'Delay_2016_normalized_value': -0.8705272692129561}\n"
     ]
    }
   ],
   "source": [
    "#roadTraffic\n",
    "new_collection = db.roadTraffic\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'road_traffic_2015': collect['Delay_2015_normalized_value']}})\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'road_traffic_2016': collect['Delay_2016_normalized_value']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'road_traffic_2015':collect['Delay_2015_normalized_value']}})\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'road_traffic_2016':collect['Delay_2016_normalized_value']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('5a26b5b62ece256aa224e4dc'), 'city_name': 'Aberdeen', 'total_jobs': 176400.0, 'total_jobs_normalized_value': -0.13139689528109025}\n"
     ]
    }
   ],
   "source": [
    "#TotalJobs\n",
    "new_collection = db.TotalJobs\n",
    "print(new_collection.find_one())\n",
    "collects = new_collection.find()\n",
    "for collect in collects:\n",
    "    result = collection.update_many({'region': collect['city_name']},{'$inc': {'total_jobs': collect['total_jobs_normalized_value']}})\n",
    "    if result.matched_count == 0:\n",
    "        result1 = collection.update_one({'city_name': collect['city_name']},{'$inc': {'total_jobs':collect['total_jobs_normalized_value']}})\n",
    "#         print(result1.matched_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "all_found =  collection.find({\n",
    "                            'house_price':{'$exists':'true'},\n",
    "                              'total_jobs':{'$exists':'true'},\n",
    "                              'school_number':{'$exists':'true'},\n",
    "                              'unemployment':{'$exists':'true'},\n",
    "                              'traffic_noise':{'$exists':'true'},\n",
    "                              'hospitals_number':{'$exists':'true'},\n",
    "                              'population':{'$exists':'true'},\n",
    "                              'GVA':{'$exists':'true'},\n",
    "                              'stations_number':{'$exists':'true'},\n",
    "                              'happiness':{'$exists':'true'},\n",
    "                              'pubs_number':{'$exists':'true'},\n",
    "                              'road_traffic_2016':{'$exists':'true'},\n",
    "#                               'best_Uni_ranking':{'$exists':'true'}\n",
    "                             })\n",
    "\n",
    "print(all_found.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        GVA  best_Uni_ranking  hospitals_number  house_price  population  \\\n",
      "0  0.168831          0.797753          0.177215    -0.570112    1.567995   \n",
      "1  0.168831          0.797753          0.177215    -0.570112    1.567995   \n",
      "2  0.201299          0.000000          0.000000    -1.978730   -0.299514   \n",
      "3  0.139610          0.258427          0.088608    -0.807119   -0.011484   \n",
      "4  0.139610          0.258427          0.088608    -0.807119   -0.011484   \n",
      "\n",
      "   pubs_number  road_traffic_2015  road_traffic_2016  school_number  \\\n",
      "0     0.644543           0.429722           0.441331       0.266980   \n",
      "1     0.644543           0.429722           0.441331       0.266980   \n",
      "2     0.151917          -0.499028          -0.485096       0.030303   \n",
      "3     0.699115           0.032681           0.095372       0.086207   \n",
      "4     0.699115           0.032681           0.095372       0.092476   \n",
      "\n",
      "   stations_number  total_jobs  traffic_noise  unemployment  \n",
      "0         0.578947    1.188895       1.084697      1.369535  \n",
      "1         0.578947    1.188895       1.084697      1.369535  \n",
      "2         0.070175   -0.304352      -0.242519     -0.711066  \n",
      "3         0.228070   -0.097214       0.527049      1.617838  \n",
      "4         0.228070   -0.097214       0.527049      1.617838  \n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import numpy\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import sklearn\n",
    "\n",
    "filter_ = {\n",
    "                            'house_price':{'$exists':'true'},\n",
    "                              'total_jobs':{'$exists':'true'},\n",
    "                              'school_number':{'$exists':'true'},\n",
    "                              'unemployment':{'$exists':'true'},\n",
    "                              'traffic_noise':{'$exists':'true'},\n",
    "                              'hospitals_number':{'$exists':'true'},\n",
    "                              'population':{'$exists':'true'},\n",
    "                              'GVA':{'$exists':'true'},\n",
    "                              'stations_number':{'$exists':'true'},\n",
    "                              'happiness':{'$exists':'true'},\n",
    "                              'pubs_number':{'$exists':'true'},\n",
    "                              'road_traffic_2016':{'$exists':'true'},\n",
    "#                               'best_Uni_ranking':{'$exists':'true'}\n",
    "                             }\n",
    "\n",
    "all_found = collection.find(filter_)\n",
    "\n",
    "\n",
    "# read data to pandas\n",
    "data = pd.DataFrame(list(all_found))\n",
    "# print(data[0:10])\n",
    "\n",
    "# create target variable\n",
    "target = data.iloc[:, 4]\n",
    "# print(target)\n",
    "\n",
    "\n",
    "# remove happiness from data\n",
    "data = data.drop(['happiness'], axis=1)\n",
    "\n",
    "data = data.fillna(0)\n",
    "# create target variable\n",
    "# print(data[0:10])\n",
    "\n",
    "# remove some columns\n",
    "data = data.drop(['_id', 'city_name', 'latitude', 'longitude', 'region', 'sample', 'uk_region'], axis=1)\n",
    "\n",
    "print(data[0:5])\n",
    "\n",
    "data_pandas = data\n",
    "# convert both to Numpy array representation\n",
    "data = data.as_matrix()\n",
    "target = target.as_matrix()\n",
    "print(type(data))\n",
    "print(type(target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e-05   1.08984148e-05   1.18775445e-05   1.29446407e-05\n",
      "   1.41076064e-05   1.53750546e-05   1.67563723e-05   1.82617896e-05\n",
      "   1.99024558e-05   2.16905218e-05   2.36392304e-05   2.57630139e-05\n",
      "   2.80776012e-05   3.06001344e-05   3.33492958e-05   3.63454458e-05\n",
      "   3.96107745e-05   4.31694651e-05   4.70478737e-05   5.12747243e-05\n",
      "   5.58813215e-05   6.09017821e-05   6.63732883e-05   7.23363628e-05\n",
      "   7.88351687e-05   8.59178369e-05   9.36368225e-05   1.02049293e-04\n",
      "   1.11217553e-04   1.21209502e-04   1.32099143e-04   1.43967126e-04\n",
      "   1.56901346e-04   1.70997595e-04   1.86360272e-04   2.03103154e-04\n",
      "   2.21350242e-04   2.41236676e-04   2.62909736e-04   2.86529935e-04\n",
      "   3.12272209e-04   3.40327206e-04   3.70902706e-04   4.04225154e-04\n",
      "   4.40541340e-04   4.80120226e-04   5.23254938e-04   5.70264936e-04\n",
      "   6.21498382e-04   6.77334716e-04   7.38187469e-04   8.04507324e-04\n",
      "   8.76785453e-04   9.55557156e-04   1.04140582e-03   1.13496727e-03\n",
      "   1.23693440e-03   1.34806242e-03   1.46917434e-03   1.60116714e-03\n",
      "   1.74501837e-03   1.90179340e-03   2.07265333e-03   2.25886358e-03\n",
      "   2.46180322e-03   2.68297527e-03   2.92401774e-03   3.18671582e-03\n",
      "   3.47301508e-03   3.78503590e-03   4.12508913e-03   4.49569324e-03\n",
      "   4.89959297e-03   5.33977966e-03   5.81951336e-03   6.34234706e-03\n",
      "   6.91215290e-03   7.53315095e-03   8.20994038e-03   8.94753358e-03\n",
      "   9.75139324e-03   1.06274728e-02   1.15822607e-02   1.26228282e-02\n",
      "   1.37568817e-02   1.49928203e-02   1.63397975e-02   1.78077891e-02\n",
      "   1.94076672e-02   2.11512808e-02   2.30515432e-02   2.51225279e-02\n",
      "   2.73795730e-02   2.98393944e-02   3.25202097e-02   3.54418735e-02\n",
      "   3.86260238e-02   4.20962430e-02   4.58782318e-02   5.00000000e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.091184676136104759, 0.026422038144551172, 0.02675527745416478, 0.030394912892515495, 0.019912608540440829, 0.035709688698225779, 0.040077627488895477, 0.021256235650090431, 0.02431419779192999, 0.031495444685248092, 0.018494439370819616, 0.027679344588797655, 0.052059952240394156, 0.019028830906831051, 0.023220419646009422, 0.03207660575432586, 0.025046531162817541, 0.017005945402681421, 0.034168363015671735, 0.022299265022200133, 0.025910164298033011, 0.021505359280325039, 0.036745091153989412, 0.025335494295371953, 0.017803233350119463, 0.026853542272232661, 0.017629648831774578, 0.02090014652171493, 0.023700769799698942, 0.021603476154852971, 0.02450771614620563, 0.025780902059304167, 0.028395072695834057, 0.0258788309317039, 0.027860831799441779, 0.024104101358494313, 0.020406281956510071, 0.030326748034332239, 0.025767167074333502, 0.019925556376972825, 0.029523647167043005, 0.019454168512262712, 0.020198936749293545, 0.018276371515082282, 0.027711978719558158, 0.020314050629859019, 0.016954402132725623, 0.02367458651622029, 0.022983262541193757, 0.016960494057850974, 0.017908697472792844, 0.02211047629252719, 0.027232574094234373, 0.019771641015861038, 0.020874651808398377, 0.019414290494968466, 0.017743489549561821, 0.021758607115594415, 0.025275575660997696, 0.019984763428109596, 0.017107519731477686, 0.028836545732317264, 0.020868779466525295, 0.017530069220314071, 0.022696671374987754, 0.020807838231694388, 0.01737932420253379, 0.019004123578348638, 0.018216998111605608, 0.017745482901543222, 0.018708412720290096, 0.021794860797700454, 0.019042268492628821, 0.021229757991307191, 0.022235937729914695, 0.026188080288818753, 0.021574322887593492, 0.02119858586717692, 0.022777074487563602, 0.024092632389216176, 0.024049926127315008, 0.026578622624636748, 0.024646664658646712, 0.026369099680905006, 0.028514315420075549, 0.030085054415319442, 0.030051623688996561, 0.030209285926733543, 0.032644768725570768, 0.029432720230532602, 0.029791896404033253, 0.0324837507877202, 0.029949651730994079, 0.03114565075905084, 0.03160855852120658, 0.031525854577262501, 0.032795011310450616, 0.033481434982814938, 0.035488830397613302, 0.03646800140237208]\n",
      "46\n",
      "0.000523254937813\n",
      "[-0.4861390780151192, -0.0, 0.26843660036074174, 0.029040155585504004, 0.00839536403618197, -0.20491619562487373, -0.13375227060868156, 0.0, 0.0, -0.6634847868150923, -0.0, 0.14061089056403175, -0.08939884684878738]\n",
      "0.672248437408\n"
     ]
    }
   ],
   "source": [
    "# run lasso for feature selection\n",
    "clf = linear_model.Lasso(alpha=0.0005)\n",
    "clf.fit(data, target)\n",
    "\n",
    "alphas = numpy.geomspace(0.00001, 0.05, num=100)\n",
    "print(alphas)\n",
    "\n",
    "error = []\n",
    "for i in alphas:\n",
    "    \n",
    "    mean_error = []\n",
    "    \n",
    "#     cross validation\n",
    "    kf = sklearn.model_selection.KFold(4, shuffle=True)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        Y_train, Y_test = target[train_index], target[test_index]\n",
    "        \n",
    "#         train model\n",
    "        clf = linear_model.Lasso(alpha=i)\n",
    "        clf.fit(X_train, Y_train)\n",
    "        \n",
    "#         error\n",
    "        mean_error.append(sklearn.metrics.mean_squared_error(Y_test, clf.predict(X_test)))\n",
    "    \n",
    "#     error\n",
    "    error.append(numpy.mean(mean_error))\n",
    "\n",
    "    \n",
    "print(error)\n",
    "print(error.index(min(error)))\n",
    "print(alphas[error.index(min(error))])\n",
    "\n",
    "# alpha\n",
    "alpha = alphas[error.index(min(error))]\n",
    "\n",
    "clf = linear_model.Lasso(alpha=alpha)\n",
    "clf.fit(data, target)\n",
    "\n",
    "\n",
    "weights = clf.coef_\n",
    "print(weights.tolist())\n",
    "print(clf.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the features\n",
    "boundary = 0.000001\n",
    "\n",
    "selectedFeatures = []\n",
    "data_deleted = data_pandas\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    if abs(weights[i])> boundary:\n",
    "        selectedFeatures.append(data_pandas.columns.values[i])\n",
    "    else:\n",
    "        data_deleted = data_deleted.drop(data_pandas.columns.values[i],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.4861550509621856, 0.2677746129561489, 0.029047519576520076, 0.008429165974621398, -0.20482285570938416, -0.1337217895737904, -0.6633779218715319, 0.14056782165410728, -0.08940774248946816]\n",
      "0.672256331136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['GVA', 'hospitals_number', 'house_price', 'population', 'pubs_number',\n",
       "       'road_traffic_2015', 'stations_number', 'traffic_noise',\n",
       "       'unemployment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert both to Numpy array representation\n",
    "data = data_deleted.as_matrix()\n",
    "clf = linear_model.Lasso(alpha=alpha)\n",
    "clf.fit(data, target)\n",
    "weights = clf.coef_\n",
    "print(weights.tolist())\n",
    "print(clf.intercept_)\n",
    "data_deleted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['population',\n",
      " 'house_price',\n",
      " 'unemployment',\n",
      " 'road_traffic_2015',\n",
      " 'traffic_noise',\n",
      " 'pubs_number',\n",
      " 'hospitals_number',\n",
      " 'GVA',\n",
      " 'stations_number']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'GVA': -0.4861550509621856,\n",
       " 'hospitals_number': 0.2677746129561489,\n",
       " 'house_price': 0.029047519576520076,\n",
       " 'population': 0.008429165974621398,\n",
       " 'pubs_number': -0.20482285570938416,\n",
       " 'road_traffic_2015': -0.1337217895737904,\n",
       " 'stations_number': -0.6633779218715319,\n",
       " 'traffic_noise': 0.14056782165410728,\n",
       " 'unemployment': -0.08940774248946816}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# save features to dictionary\n",
    "values = weights.tolist()\n",
    "keys = data_deleted.columns\n",
    "\n",
    "count = 0\n",
    "valueFeatures = {}\n",
    "for key in keys:\n",
    "    valueFeatures[key] = values[count]\n",
    "    count += 1\n",
    "\n",
    "\n",
    "sortedFeatures = sorted(valueFeatures, key=lambda dict_key: abs(valueFeatures[dict_key]))\n",
    "    \n",
    "pprint(sortedFeatures)\n",
    "valueFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
